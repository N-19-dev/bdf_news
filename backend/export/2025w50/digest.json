{
  "ai_data_engineering": [
    {
      "url": "https://aws.amazon.com/blogs/big-data/how-bayer-transforms-pharma-rd-with-a-cloud-based-data-science-ecosystem-using-amazon-sagemaker/",
      "title": "How Bayer transforms Pharma R&D with a cloud-based data science ecosystem using Amazon SageMaker",
      "summary": "In this post, we discuss how Bayer AG used the next generation of Amazon SageMaker to build a cloud-based Pharma R&D Data Science Ecosystem (DSE) that unified data ingestion, storage, analytics, and AI/ML workflows.",
      "published_ts": 1765580785,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://blog.cloudflare.com/react2shell-rsc-vulnerabilities-exploitation-threat-brief/",
      "title": "React2Shell and related RSC vulnerabilities threat brief: early exploitation activity and threat actor techniques",
      "summary": "Early activity indicates that threat actors quickly integrated this vulnerability into their scanning and reconnaissance routines and targeted critical infrastructure including nuclear fuel, uranium and rare earth elements. We outline the tactics they appear to be using and how Cloudflare is protecting customers.",
      "published_ts": 1765470000,
      "source_name": "Cloudflare Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://huggingface.co/blog/ggml-org/model-management-in-llamacpp",
      "title": "New in llama.cpp: Model Management",
      "summary": "New in llama.cpp: Model Management\nllama.cpp server\nnow ships with\nrouter mode\n, which lets you dynamically load, unload, and switch between multiple models without restarting.\nReminder: llama.cpp server is a lightweight, OpenAI-compatible HTTP server for running LLMs locally.\nThis feature was a pop",
      "published_ts": 1765468064,
      "source_name": "Hugging Face Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/ias-and-personas--vers-un-nouvel-extreme-persona",
      "title": "IAs  and  Personas : vers un nouvel extrême persona ?",
      "summary": "À l’heure où l’IA transforme nos usages, cet article explore son rôle dans nos méthodes de conception, ainsi que son potentiel d’inclusion et d’accessibilité. Il invite à considérer les IA comme de nouveaux utilisateurs dans nos démarches de design et de développement.",
      "published_ts": 1765459030,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://stripe.com/blog/agentic-commerce-suite",
      "title": "Introducing the Agentic Commerce Suite: A complete solution for selling on AI agents",
      "summary": "Today, we’re introducing the Agentic Commerce Suite: a new solution that gets your business agent-ready. It enables you to sell on AI agents more easily by making your products discoverable, simplifying your checkout, and allowing you to accept agentic payments via a single integration.",
      "published_ts": 1765411200,
      "source_name": "Stripe Engineering Blog",
      "content_type": "technical"
    },
    {
      "url": "https://huggingface.co/blog/hf-skills-training-codex",
      "title": "Codex is Open Sourcing AI models",
      "summary": "Codex is Open Sourcing AI models\nBuilding on our work to get\nClaude Code\nto train open source models, we are now getting\nCodex\nto go further. We gave Codex access to the\nHugging Face Skills\nrepository, which contains skills for Machine Learning and AI tasks such as training or evaluating models. Wit",
      "published_ts": 1765411200,
      "source_name": "Hugging Face Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.langchain.com/debugging-deep-agents-with-langsmith/",
      "title": "Debugging Deep Agents with LangSmith",
      "summary": "Debugging is the process of finding and fixing errors. This is a critical step in software engineering, and even more critical in agent engineering . One of the key capabilities of LangSmith is tooling to debug LLM applications. Today we are doubling down on solving that problem for the new wave",
      "published_ts": 1765386499,
      "source_name": "LangChain Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.langchain.com/introducing-polly-your-ai-agent-engineer/",
      "title": "Introducing Polly: Your AI Agent Engineer",
      "summary": "Today, we're launching Polly: an AI-powered assistant built directly into LangSmith that helps you debug, analyze, and improve your agents. And yes, we see the irony: we're adding an agent to a product for building agents. We've spent a lot of time working with",
      "published_ts": 1765386468,
      "source_name": "LangChain Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/faire-confiance--reinventer-l'experience-utilisateur-a-l'ere-l'ia",
      "title": "Faire confiance : Réinventer l'expérience utilisateur à l'ère l’IA",
      "summary": "À l’ère où l’IA transforme la manière d’appréhender les produits en instaurant une vraie relation homme–machine, cet article montre pourquoi créer une relation de confiance devient indispensable, et propose une grille de lecture et des leviers concrets pour concevoir et mesurer la confiance.",
      "published_ts": 1765381270,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://www.dataiku.com/stories/blog/wisr",
      "title": "How Wisr Uses AI Agents for Faster, Value-Driven Lending Decisions",
      "summary": "Wisr uses Dataiku-powered AI agents to classify cases, surface relevant precedent, and give BDMs clearer, faster, and more consistent value-driven decisions. 40%-50% reduction in manual review time for exception cases 20-30 hours saved per month for senior assessors",
      "published_ts": 1765380352,
      "source_name": "Dataiku Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/du-design-a-la-strategie-produit--detourner-la-discovery-pour-decider-autrement-ce-que-j'ai-retenu-du-talk-de-laura-crispain-(school-of-product-2025)",
      "title": "School of Product 2025—  Du design à la stratégie produit — Ce que j’ai retenu du talk de Laura Krispin",
      "summary": "On présente souvent la Product Discovery comme un filet de sécurité : un moyen d’éviter de sortir un produit qui ne sera ni utilisé, ni acheté. Cependant à la School of Product, Laura Krispin nous a montré autre chose : une discovery qui sert à décider, pas seulement à valider.",
      "published_ts": 1765354630,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/artois-university-elevates-curriculum-with-gitlab-ultimate-for-education/",
      "title": "Artois University elevates research and curriculum with GitLab Ultimate for Education",
      "summary": "Leading academic institutions face a critical challenge: how to provide thousands of students and researchers with industry-standard, full-featured DevSecOps tools without compromising institutional control. Many start with basic version control, but the modern curriculum demands integrated capabilities for planning, security, and advanced CI/CD. The GitLab for Education program is designed to solve this by providing access to GitLab Ultimate for qualifying institutions, allowing them to scale their operations and elevate their academic offerings. This article showcases a powerful success story from the Centre de Recherche en Informatique de Lens (CRIL) , a joint laboratory of Artois University and CNRS in France. After years of relying solely on GitLab Community Edition (CE), the university's move to GitLab Ultimate through the GitLab for Education program immediately unlocked advanced capabilities, transforming their teaching, research, and contribution workflows virtually overnight. This story demonstrates why GitLab Ultimate is essential for institutions seeking to deliver advanced computer science and research curricula. GitLab Ultimate unlocked: Managing scale and driving academic value Artois University's self-managed GitLab instance is a large-scale operation, supporting nearly 3,000 users across approximately 19,000 projects , primarily serving computer science students and researchers. While GitLab Community Edition was robust, the upgrade to GitLab Ultimate provided the sophisticated tooling necessary for managing this scale and facilitating advanced university-level work. \"We can see the difference,\" says Daniel Le Berre, head of research at CRIL and the instance maintainer. \"It's a completely different product. Each week reveals new features that directly enhance our productivity and teaching.\" The institution joined the GitLab for Education program specifically because it covers both instructional and non-commercial research use cases and offers full access to Ultimate's features, removing significant cost barriers. Key GitLab Ultimate benefits for students and researchers Advanced project management at scale: Master's students now benefit from GitLab Ultimate's project planning features . This enables them to structure, track, and manage complex, long-term research projects using professional methodologies like portfolio management and advanced issue tracking that seamlessly roll up across their thousands of projects. Enhanced visibility: Features like improved dashboards and code previews directly in Markdown files dramatically streamline tracking and documentation review, reducing administrative friction for both instructors and students managing large project loads. Comprehensive curriculum: From concepts to continuous delivery GitLab Ultimate is deeply integrated into the computer science curriculum, moving students beyond simple git commands to practical DevSecOps implementation . Git fundamentals: Students begin by visualizing concepts using open-source tools to master Git concepts. Full CI/CD implementation: Students use GitLab CI for rigorous Test-Driven Development (TDD) in their software projects. They learn to build, test, and perform quality assurance using unit and integration testing pipelines—core competency made seamless by the integrated platform. DevSecOps for research and documentation: The university teaches students that DevSecOps principles are vital for all collaborative work. Inspired by earlier work in Delft, students manage and produce critical research documentation (PDFs from Markdown files) using GitLab, incorporating quality checks like linters and spell checks directly in the CI pipeline. This ensures high-quality, reproducible research output. Future-proofing security skills: The GitLab Ultimate platform immediately positions the institution to incorporate advanced DevSecOps features like SAST and DAST scanning as their research and development code projects grow, ensuring students are prepared for industry security standards. Accelerating open source contributions with GitLab Duo Access to the full GitLab platform, including our AI capabilities, has empowered students to make impactful contributions to the wider open source community faster than ever before. Two Master's students recently completed direct contributions to the GitLab product, adding the ORCID identifier into user profiles. Working on GitLab.com, they leveraged GitLab Duo's AI chat and code suggestions to navigate the codebase efficiently. \"This would not have been possible without GitLab Duo,\" Daniel Le Berre notes. \"The AI features helped students, who might have lacked deep codebase knowledge, deliver meaningful contributions in just two weeks.\" This demonstrates how providing students with cutting-edge tools accelerates their learning and impact , allowing them to translate classroom knowledge into real-world contributions immediately. Empowering open research and institutional control The stability of the self-managed instance at Artois University is key to its success. This model guarantees institutional control and stability — a critical factor for long-term research preservation. The institution's expertise in this area was recently highlighted in a major 2024 study led by CRIL, titled: \" Higher Education and Research Forges in France - Definition, uses, limitations encountered and needs analysis \" ( Project on GitLab ). The research found that the vast majority of public forges in French Higher Education and Research relied on GitLab . This finding underscores the consensus among academic leaders that self-hosted solutions are essential for data control and longevity , especially when compared to relying on external, commercial forges. Unlock GitLab Ultimate for your institution today The success story of Artois University's CRIL proves the transformative power of the GitLab for Education program. By providing free access to GitLab Ultimate , we enable large-scale institutions to: Deliver a modern, integrated DevSecOps curriculum. Support advanced, collaborative research projects with Ultimate planning features. Empower students to make AI-assisted open source contributions. Maintain institutional control and data longevity. If your academic institution is ready to equip its students and researchers with the complete DevSecOps platform and its most advanced features, we invite you to join the program. The program provides free access to GitLab Ultimate for qualifying instructional and non-commercial research use cases. Apply now online .",
      "published_ts": 1765324800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/new-wave-of-fake-job-scams-impersonating-recruiters/",
      "title": "New wave of fake job scams impersonating recruiters",
      "summary": "Job seekers are being targeted by scammers impersonating recruiters at tech companies, including GitLab, through email, LinkedIn, and video conferencing platforms. These scams misuse GitLab’s name, logo, and team member identities to create the illusion of legitimate hiring activity. Victims have reported receiving fake interview invitations, employment offers, and onboarding documents, often followed by requests for payment or personal information. These campaigns are not affiliated with GitLab in any way. What’s new with this wave Recent incidents differ from earlier scams by introducing new domains and tactics, including: Use of unauthorized domains such as gitlab[.]careers and careers-gitlab[.]com References to fake certifications like “CPD USA Certification” Fake recruiter profiles on LinkedIn and Teams impersonating GitLab HR staff Requests for sensitive information or upfront “equipment” payments after fake interviews These impersonators are becoming more sophisticated, using corporate-style emails, authentic-looking offer letters, and realistic video interview invitations to gain trust. Common warning signs Candidates should be cautious if they encounter any of the following: The email domain is not @gitlab.com (e.g., Gmail, Outlook, or lookalike domains). The recruiter requests you to pay for equipment, certification, or background checks. The communication happens only through chat, without verified GitLab calendar invites. The job listing does not appear on the official GitLab careers page. The recruiter refuses to verify their identity via a GitLab.com address or directs you to external URLs unrelated to GitLab. GitLab’s official recruiting process GitLab’s hiring process is fully remote but transparent and verifiable. All communications come from official @gitlab.com email addresses. Interviews are conducted via Zoom, not Microsoft Teams or WhatsApp. GitLab never requests payment, purchases, or certification fees during recruitment. Legitimate offers and onboarding steps are handled securely through GitLab systems. For details on how we hire, please refer to our Candidate Handbook . What GitLab is doing GitLab’s Security and People teams are actively investigating and reporting fake recruiting domains and profiles to hosting providers and social networks. We continue to collaborate with legal, communications, and platform partners to remove fraudulent content and notify affected individuals. If you see something suspicious, let us know at security@gitlab.com . Anyone can report suspicious recruiting activity for review by our Security Incident Response Team. How to protect yourself If you receive suspicious communication that claims to be from GitLab: Verify the sender’s email domain — it should always end in @gitlab.com . Confirm job postings directly on about.gitlab.com/jobs. Avoid sending personal or financial information to unverified recruiters. Report any suspicious domains or messages to security@gitlab.com . For additional information on avoiding job scams, see these trusted resources: Candidate Handbook Online employment scam resources – FTC If you believe you’ve been targeted by a fake GitLab recruiter, please **report it immediately to security@gitlab.com so our team can investigate.",
      "published_ts": 1765324800,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://www.databricks.com/blog/introducing-databricks-genai-partner-accelerators-data-engineering-migration",
      "title": "Introducing Databricks GenAI Partner Accelerators for Data Engineering & Migration",
      "summary": "Enterprises face increasing pressure to modernize their data stacks. Teams need to...",
      "published_ts": 1765317600,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/introducing-apache-iceberg-materialized-views-in-aws-glue-data-catalog/",
      "title": "Introducing Apache Iceberg materialized views in AWS Glue Data Catalog",
      "summary": "Hundreds of thousands of customers build artificial intelligence and machine learning (AI/ML) and analytics applications on AWS, frequently transforming data through multiple stages for improved query performance—from raw data to processed datasets to final analytical tables. Data engineers must solve complex problems, including detecting what data has changed in base tables, writing and maintaining transformation […]",
      "published_ts": 1765316211,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/ia--risque-d'asservissement-et-d'erosion-des-competences-comment-preserver-la-maitrise-du-geste",
      "title": "IA : risque d’asservissement et d’érosion des compétences - comment préserver la maîtrise du geste ?",
      "summary": "l’IA n’est qu’un outil, à maîtriser en gardant nos capacités d’apprentissage et nos compétences de pratique. Repassons “en mode manuel” de temps à autre pour rester en alerte et éviter l'asservissement. C’est ce qui permet de garder la maîtrise, la créativité, nos réflexes ainsi que nos motivations. Inspirons nous de l'aviation ou de l'automobile.",
      "published_ts": 1765300810,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://engineering.atspotify.com/2025/12/feedback-loops-background-coding-agents-part-3/",
      "title": "Background Coding Agents: Predictable Results Through Strong Feedback Loops (Part 3)",
      "summary": "The system we built to ensure our AI agents produce predictable, trustworthy code. The post Background Coding Agents: Predictable Results Through Strong Feedback Loops (Part 3) appeared first on Spotify Engineering .",
      "published_ts": 1765293259,
      "source_name": "Spotify Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://www.dataiku.com/stories/blog/stop-building-rag-chatbots",
      "title": "Why You Should Stop Building RAG Chatbots From Scratch",
      "summary": "Retrieval-augmented generation (RAG) chatbots fuse large language models (LLMs) with your actual data, so answers are smart and grounded. Instead of guessing, they retrieve real context, docs, logs, FAQs, and generate responses backed by facts with fewer hallucinations, faster iteration, and AI that behaves less like an experiment and more like a product.",
      "published_ts": 1765288980,
      "source_name": "Dataiku Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/cr-school-of-product-2025-moi-emmanuelle--sourde-malvoyante...-et-utilisatrice-de-vos-produits",
      "title": "CR School of Product 2025 - Moi, Emmanuelle : sourde, malvoyante… et utilisatrice de vos produits",
      "summary": "Lors de l’édition 2025 de la School of Product, un talk m’a particulièrement marqué : celui d’Emmanuelle, développeuse depuis treize ans, experte en accessibilité et sourde de naissance. À travers son parcours, elle offre un éclairage précieux sur la manière dont la technologie a transformé sa vie quotidienne — mais aussi sur ses limites et sur la",
      "published_ts": 1765287237,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://www.databricks.com/blog/powering-growth-how-data-and-ai-are-rewiring-productivity-banking-and-payments",
      "title": "Powering Growth: How Data and AI Are Rewiring Productivity in Banking and Payments",
      "summary": "Banks are being challenged to do more with less. What’s at stake?Today’s banks are...",
      "published_ts": 1765239300,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/school-of-product-2025-compte-rendu-l'humanite-a-t-elle-les-moyens-de-s'offrir-l'ia",
      "title": "School Of Product 2025 - Compte Rendu - L’humanité a-t-elle les moyens de s’offrir l’IA ?",
      "summary": "Ce que nous retenons du talk de Tristan Nitot à la School of Product\nLors de l’édition récente de la School of Product, Tristan Nitot a pris la parole autour d’une question percutante :\n>\n“L’humanité a-t-elle les moyens de s’offrir l’IA ?”\nCe talk n’était ni alarmiste ni béatement techno-enthousiast",
      "published_ts": 1765205890,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://blog.octo.com/octoune-vie-ponctuee-par-la-resilience-et-la-performance--la-school-of-product-2025-cr-de-clarisse-agbegnenou",
      "title": "Une vie ponctuée par la résilience et la performance  : La School of Product 2025 - CR de Clarisse Agbegnenou",
      "summary": "Clarisse Agbegnenou, multiple championne olympique, nous invite à repenser l'équilibre fondamental entre performance et bien-être. À travers le partage de son expérience personnelle, elle établit des parallèles éclairants avec les défis du monde de la gestion de produit.",
      "published_ts": 1765184726,
      "source_name": "OCTO Talks!",
      "content_type": "technical"
    },
    {
      "url": "https://dlthub.com/blog/data-contracts-agreement-vs-enforcement",
      "title": "Data contract agreement vs enforcement",
      "summary": "Data contracts keep systems predictable by pairing clear rules with checks that catch bad data before it flows downstream.",
      "published_ts": 1765152000,
      "source_name": "dlt Blog",
      "content_type": "technical"
    }
  ],
  "cloud_infra_observability": [
    {
      "url": "https://azure.microsoft.com/en-us/blog/introducing-gpt-5-2-in-microsoft-foundry-the-new-standard-for-enterprise-ai/",
      "title": "Introducing GPT-5.2 in Microsoft Foundry: The new standard for enterprise AI",
      "summary": "Discover GPT‑5.2 in Microsoft Foundry—the next standard for enterprise AI. Learn how advanced reasoning, agentic execution, and compliance-ready features empower developers and technical leaders. The post Introducing GPT-5.2 in Microsoft Foundry: The new standard for enterprise AI appeared first on Microsoft Azure Blog .",
      "published_ts": 1765477085,
      "source_name": "Azure Blog",
      "content_type": "technical"
    },
    {
      "url": "https://azure.microsoft.com/en-us/blog/actioning-agentic-ai-5-ways-to-build-with-news-from-microsoft-ignite-2025/",
      "title": "Actioning agentic AI: 5 ways to build with news from Microsoft Ignite 2025",
      "summary": "Energy at Microsoft Ignite was electric. Over 20,000 attendees gathered in San Francisco, with 200,000 digital participants joining us to explore the future of cloud and AI. The post Actioning agentic AI: 5 ways to build with news from Microsoft Ignite 2025 appeared first on Microsoft Azure Blog .",
      "published_ts": 1765386000,
      "source_name": "Azure Blog",
      "content_type": "technical"
    },
    {
      "url": "https://huggingface.co/blog/ServiceNow-AI/apriel-1p6-15b-thinker",
      "title": "Apriel-1.6-15b-Thinker: Cost-efficient Frontier Multimodal Performance",
      "summary": "Apriel-1.6-15b-Thinker: Cost-efficient Frontier Multimodal Performance\nWe release\nApriel-1.6-15b-Thinker\n, a 15-billion parameter multimodal reasoning model in ServiceNow’s Apriel SLM series which achieves SOTA performance against models 10 times it's size. Apriel-1.6 builds on top of\nApriel-1.5-15b",
      "published_ts": 1765310816,
      "source_name": "Hugging Face Blog",
      "content_type": "technical"
    },
    {
      "url": "https://azure.microsoft.com/en-us/blog/microsofts-commitment-to-supporting-cloud-infrastructure-demand-in-the-united-states/",
      "title": "Microsoft’s commitment to supporting cloud infrastructure demand in the United States",
      "summary": "Today, we are sharing progress on our infrastructure expansions across the United States that are supporting the tremendous growth in customer demand for cloud and AI services. The post Microsoft’s commitment to supporting cloud infrastructure demand in the United States appeared first on Microsoft Azure Blog .",
      "published_ts": 1765296000,
      "source_name": "Azure Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.cloudflare.com/shift-left-enterprise-scale/",
      "title": "Shifting left at enterprise scale: how we manage Cloudflare with Infrastructure as Code",
      "summary": "Cloudflare has shifted to Infrastructure as Code and policy enforcement to manage internal Cloudflare accounts. This new architecture uses Terraform, custom tooling, and Open Policy Agent to enforce security baselines and increase engineering velocity.",
      "published_ts": 1765260000,
      "source_name": "Cloudflare Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/build-billion-scale-vector-databases-in-under-an-hour-with-gpu-acceleration-on-amazon-opensearch-service/",
      "title": "Build billion-scale vector databases in under an hour with GPU acceleration on Amazon OpenSearch Service",
      "summary": "AWS recently announced the general availability of GPU-accelerated vector (k-NN) indexing on Amazon OpenSearch Service. You can now build billion-scale vector databases in under an hour and index vectors up to 10 times faster at a quarter of the cost. This feature dynamically attaches serverless GPUs to boost domains and collections running CPU-based instances. With […]",
      "published_ts": 1765238239,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-reinvent-keynote-recap-on-demand-videos-and-more-december-8-2025/",
      "title": "AWS Weekly Roundup: AWS re:Invent keynote recap, on-demand videos, and more (December 8, 2025)",
      "summary": "The week after AWS re:Invent builds on the excitement and energy of the event and is a good time to learn more and understand how the recent announcements can help you solve your challenges and unlock new opportunities. As usual, we have you covered with our top announcements of AWS re:Invent 2025 that you can […]",
      "published_ts": 1765213529,
      "source_name": "AWS Blog",
      "content_type": "technical"
    }
  ],
  "data_modeling_governance": [
    {
      "url": "https://www.uber.com/blog/blazing-fast-olap-on-ubers-inventory-and-catalog-data-with-apache-pinot/",
      "title": "Blazing Fast OLAP on Uber’s Inventory and Catalog Data with Apache Pinot™",
      "summary": "Discover how Uber used Apache Pinot™ to build a real-time index on its massive inventory of billions of items to power search use cases, internal tools, and operational workflows.",
      "published_ts": 1765288800,
      "source_name": "Uber Engineering Blog",
      "content_type": "technical"
    }
  ],
  "etl_orchestration": [
    {
      "url": "https://dagster.io/blog/deepdive-recap-data-reliability",
      "title": "Building Reliable Data Platforms with Dagster",
      "summary": "Use Dagster to enforce data quality rules at every step of the pipeline, improving platform reliability and reducing downstream data issues.",
      "published_ts": 1765554388,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/impedance-mismatch-in-data-orchestration",
      "title": "Fixing the Data Engineering Mismatch",
      "summary": "Why asset-oriented orchestration leads to better developer experience and less brittle pipelines than traditional workflow-centric systems.",
      "published_ts": 1765550380,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/scale-and-standardize-data-pipelines-with-dsl",
      "title": "Use DSLs to Standardize Your Pipelines",
      "summary": "Domain-Specific Languages help scale data platforms by allowing more users to contribute without sacrificing standardization or governance.",
      "published_ts": 1765550380,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-pipes",
      "title": "Introducing Dagster Pipes",
      "summary": "Dagster Pipes lets you securely trigger and manage external compute processes, making remote execution environments first-class citizens in your DAGs.",
      "published_ts": 1765550380,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/outbound-reporting-pipeline",
      "title": "Build an Email Reporting Pipeline",
      "summary": "Use Dagster and dynamic partitioning to build a robust outbound report delivery pipeline.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/deepdive-recap-building-a-true-data-platform",
      "title": "How to Build a True Data Platform",
      "summary": "Skip the noise of the modern data stack and build a unified, observable, and cost-effective data platform powered by Dagster orchestration.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/see-the-forest-and-trees-dagster-plus",
      "title": "See Big Picture + Details with Dagster+ Insights",
      "summary": "Use Dagster+ Insights to monitor costs, asset health, and gain observability across both macro and micro data pipeline metrics.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-ml-pipelines",
      "title": "ML Pipeline Orchestration with Dagster",
      "summary": "Orchestrate machine learning pipelines from start to finish with Dagster, training models, validating results, and monitoring outputs all in one place.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-crash-course-oct-2022",
      "title": "Dagster Crash Course: Get Started Fast",
      "summary": "Learn the basics of Dagster in under 10 minutes. This quick crash course will get your data pipelines up and running fast.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/deepdive-recap-dagster-modal",
      "title": "ML Compute with Dagster + Modal",
      "summary": "Use Dagster and Modal to build ML pipelines that scale reliably from local experiments to cloud training with full observability.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/what-is-dagster",
      "title": "What Is Dagster? Learn the Basics",
      "summary": "Dagster is a modern orchestrator for data platforms. Learn what makes it different and how it improves workflows.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/python-ci-cd-automation",
      "title": "CI/CD for Data Pipelines with Git",
      "summary": "Learn how to automate data pipeline deployment using CI/CD practices integrated with Git.",
      "published_ts": 1765478078,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/open-core-business-model-dagster",
      "title": "How Dagster Balances Open Source and SaaS",
      "summary": "Understand how Dagster separates its open-source offering from Dagster Cloud’s hosted SaaS features in a sustainable business model.",
      "published_ts": 1765478078,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-atlan-integration",
      "title": "Dagster Plus + Atlan Integration: Real-Time Event Sync",
      "summary": "Stream asset materializations, run status, and lineage from Dagster plus to Atlan in real-time. Keep your data catalog in sync with pipeline reality.",
      "published_ts": 1765470510,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.uber.com/blog/from-batch-to-streaming-accelerating-data-freshness-in-ubers-data-lake/",
      "title": "From Batch to Streaming: Accelerating Data Freshness in Uber’s Data Lake",
      "summary": "Learn how Uber moved from batch to streaming ingestion with IngestionNext, reducing data latency and unlocking real-time analytics across its petabyte-scale data lake.",
      "published_ts": 1765461600,
      "source_name": "Uber Engineering Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/deepdive-recap-evolution-data-platform",
      "title": "Evolution of the Data Platform with Dagster",
      "summary": "Dagster and SDF connect local dev environments with production pipelines, enabling full lifecycle orchestration with clear asset lineage.",
      "published_ts": 1765461515,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/orchestrating-nanochat-training-the-models",
      "title": "Training NanoChat in Dagster: Multi-Stage Model Training with RunPod GPUs",
      "summary": "Learn how to orchestrate and train each layer of your NanoChat-based model using Dagster, RunPod GPU instances, and repeatable machine-learning pipelines.",
      "published_ts": 1765389096,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-1-1-thank-u-next",
      "title": "Dagster 1.1: Declarative Scheduling",
      "summary": "Dagster 1.1 adds declarative scheduling, secrets management, and major improvements to multi-asset workflows.",
      "published_ts": 1765387457,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/training-llms",
      "title": "Train LLMs with Langchain and Dagster",
      "summary": "Combine Airbyte, Langchain, and Dagster to build robust, cost-efficient pipelines that support large language model training and iteration at scale.",
      "published_ts": 1765307461,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/pete-hunt-path-to-elementl-part2",
      "title": "Leadership Shift at Dagster Labs",
      "summary": "Dagster Labs announces a leadership transition as Pete Hunt takes over as CEO and Nick Schrock shifts focus to product innovation as CTO.",
      "published_ts": 1765306777,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/data-visibility-primer",
      "title": "What Does Data Visibility Really Mean?",
      "summary": "Hidden data causes issues. Learn how to improve visibility and reduce surprises in your analytics and engineering pipelines.",
      "published_ts": 1765305678,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/dagster-1-2-formation",
      "title": "Dagster 1.2: New Config & Integrations",
      "summary": "Dagster 1.2 introduces Pythonic config, stronger partitioned asset support, and updated integrations.",
      "published_ts": 1765305678,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.langchain.com/agent-engineering-a-new-discipline/",
      "title": "Agent Engineering: A New Discipline",
      "summary": "If you’ve built an agent, you know that the delta between “it works on my machine” and “it works in production” can be huge. Traditional software assumes you mostly know the inputs and can define the outputs. Agents give you neither: users can say",
      "published_ts": 1765297235,
      "source_name": "LangChain Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.rudderstack.com/blog/data-integration-trends",
      "title": "Data integration trends shaping 2025 and beyond",
      "summary": "Discover 2025's data integration trends, from real-time pipelines to privacy-first design.",
      "published_ts": 1765293231,
      "source_name": "Rudderstack Blog",
      "content_type": "technical"
    },
    {
      "url": "https://airbyte.com/blog/ephemeral-testing-with-generative-ai",
      "title": "Unlocking Ephemeral Testing with Generative AI: Part One | Airbyte",
      "summary": "Unlock ephemeral testing with generative AI in Part One: learn how on-demand environments cut flakiness, speed CI, and improve reliability with practical strategies, workflows, and real-world examples.",
      "published_ts": 1765238400,
      "source_name": "Airbyte Blog",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/auto-optimize-your-amazon-opensearch-service-vector-database/",
      "title": "Auto-optimize your Amazon OpenSearch Service vector database",
      "summary": "AWS recently announced the general availability of auto-optimize for the Amazon OpenSearch Service vector engine. This feature streamlines vector index optimization by automatically evaluating configuration trade-offs across search quality, speed, and cost savings. You can then run a vector ingestion pipeline to build an optimized index on your desired collection or domain. Previously, optimizing index […]",
      "published_ts": 1765238304,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://engineering.salesforce.com/how-ai-driven-testing-enabled-sub-second-latency-for-agentforce-voice/",
      "title": "How AI-Powered Testing Enabled Sub-Second Latency for Agentforce Voice",
      "summary": "In our Engineering Energizers Q&A series, we highlight the engineering minds driving innovation across Salesforce. Today, meet Angie Howard, Senior Manager of Software Engineering, who leads the team behind the Flash Reasoning Engine powering Agentforce Voice. This engine delivers natural, human-fast responses striving for sub-second Time to First Audio (TTFA) across a real-time voice pipeline. […] The post How AI-Powered Testing Enabled Sub-Second Latency for Agentforce Voice appeared first on Salesforce Engineering Blog .",
      "published_ts": 1765237906,
      "source_name": "Salesforce Engineering",
      "content_type": "technical"
    }
  ],
  "hors_sujet": [],
  "lake_storage_formats": [],
  "news": [
    {
      "url": "https://engineering.salesforce.com/4x-faster-how-ai-assisted-development-accelerated-building-new-sql-dialects-for-zero-copy-connectors/",
      "title": "4x Faster: How AI-Assisted Development Accelerated Building New SQL Dialects for Zero Copy Connectors",
      "summary": "by Per Fuchs, Steven Lockhart, and Gautam Varma. In our Engineering Energizers Q&A series, we highlight the engineering minds driving innovation across Salesforce. Today, we meet Per Fuchs, a senior software engineer with the Hyper Database team. In close collaboration with others, his team empowers Data 360 to execute analytical queries directly on 100+ external […] The post 4x Faster: How AI-Assisted Development Accelerated Building New SQL Dialects for Zero Copy Connectors appeared first on Salesforce Engineering Blog .",
      "published_ts": 1765574754,
      "source_name": "Salesforce Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/balancing-the-data-scales-centralization-vs-decentralization",
      "title": "Data Centralization vs Decentralization",
      "summary": "Explore when to centralize vs decentralize data—and how to strike the right balance in modern data architectures.",
      "published_ts": 1765551083,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.ovhcloud.com/industrial-excellence-meets-artificial-intelligence-behind-the-scenes-with-smart-datacenter/",
      "title": "Industrial Excellence meets Artificial Intelligence: Behind the Scenes with Smart Datacenter",
      "summary": "At OVHcloud, we are constantly looking for ways to improve our operations and reduce our impact on the environment. This has been a defining part of the company since 1999 and is a key part of our organisational DNA and our commercial model. We are very proud to present the new Smart Datacenter cooling system, […]",
      "published_ts": 1765550142,
      "source_name": "OVHcloud Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/introducing-dagster-labs",
      "title": "Introducing Dagster Labs",
      "summary": "Elementl has rebranded as Dagster Labs to reflect its focus on empowering data teams through world-class orchestration tools and open-source innovation.",
      "published_ts": 1765549595,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.rudderstack.com/blog/ibm-confluent-real-time-streaming-ai",
      "title": "IBM × Confluent: Is real-time streaming cool again?",
      "summary": "IBM’s Confluent acquisition shows real-time data is now essential for AI agents. Learn why customer context and streaming pipelines matter more than ever.",
      "published_ts": 1765483091,
      "source_name": "Rudderstack Blog",
      "content_type": "technical"
    },
    {
      "url": "https://azure.microsoft.com/en-us/blog/azure-storage-innovations-unlocking-the-future-of-data/",
      "title": "Azure Storage innovations: Unlocking the future of data",
      "summary": "Whether you are improving the resilience of mission-critical workloads or modernizing legacy systems; Azure Storage has a solution for you. The post Azure Storage innovations: Unlocking the future of data appeared first on Microsoft Azure Blog .",
      "published_ts": 1765468800,
      "source_name": "Azure Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.ovhcloud.com/postgresql-and-ai-the-pragmatic-path-to-smarter-data/",
      "title": "PostgreSQL and AI: The pragmatic path to smarter data",
      "summary": "Beyond the buzz: Building AI on solid foundations Artificial intelligence has quickly become the cornerstone of digital innovation. From text generation to image recognition and intelligent automation, AI is redefining how organisations extract value from data. At OVHcloud, we believe this transformation shouldn’t only belong to the tech elite – it should be open, accessible, […]",
      "published_ts": 1765465860,
      "source_name": "OVHcloud Blog",
      "content_type": "technical"
    },
    {
      "url": "https://about.gitlab.com/blog/how-we-built-and-automated-our-new-japanese-gitlab-docs-site/",
      "title": "How we built and automated our new Japanese GitLab Docs site",
      "summary": "Today we are thrilled to announce the release of GitLab product documentation in Japanese at docs.gitlab.com/ja-jp . This major step marks our first move toward making GitLab's extensive documentation accessible to our users worldwide. The unique challenge of the Japanese market Japan represents one of the world's largest economies and is a critical market for enterprise software. However, it also presents a distinctive challenge: despite its technological sophistication and massive developer community, English proficiency remains a significant barrier for many users. Japan's developers and DevSecOps teams often face challenges with English-only documentation, as indicated by the country's ranking on the EF English Proficiency Index . This language barrier can significantly impact the speed of learning and ultimately influence the decision to evaluate, adopt, and champion a platform within Japanese organizations. We've heard directly from our Japanese customers and partners that English-only documentation wasn't merely an inconvenience, it was a barrier preventing them from getting the most out of GitLab. The impact rippled through every stage of the user journey: From initial evaluation where teams struggled to assess GitLab's capabilities, to daily operations where finding solutions took longer than necessary, to staying current with new features and best practices. In a market as competitive and mature as in Japan, this language barrier directly affected GitLab's market penetration. When Japanese companies evaluate enterprise software, the availability of comprehensive Japanese documentation signals long-term commitment to the market. It demonstrates that a provider isn't just making a token effort, but is genuinely invested in supporting Japanese users throughout their entire journey. To address this challenge and demonstrate our commitment to the Japanese market, we built localization infrastructure from the ground up, integrating with how we create and maintain documentation at GitLab. Localization built on docs-as-code principles GitLab's documentation is treated like any other code contribution, residing alongside product code in GitLab projects and managed via merge requests. This system ensures documentation is version-controlled, collaboratively reviewed, and automatically tested through CI/CD pipelines, which includes checks for issues with language, formatting, and links. Both the English and Japanese documentation sites are dynamically generated using the Hugo static site generator and deployed after merging changes, guaranteeing users always access the latest information. The documentation is extensive and comprehensive, drawing content from various source projects, including GitLab, GitLab Runner, Omnibus GitLab, GitLab Charts, GitLab Operator, and GitLab CLI (glab) ( see architecture for details ). This sheer scale and rapid update velocity presented a significant localization challenge. To keep pace with the continuous evolution of these source English projects, we had to design a localization infrastructure for our GitLab product documentation that could handle these unique complexities and provide an enterprise-grade solution for a fully localized site, all while adhering to our CI/CD pipeline requirements. How we localized GitLab Documentation For our initial Japanese localization, we adopted a strategy of integrating new folders within our existing English content structure. Specifically, we introduced doc-locale/ja-jp folders within each project that stores source Markdown files. This architecture keeps the translations right alongside their source content while maintaining a clear organizational separation. Not only that, but it also enables us to apply the same robust version control, established review and collaboration workflows, and even some of the automated quality checks used for our English documentation to the translated content. This internationalization infrastructure built for Japanese documentation provides a scalable foundation for future language expansion. With the architecture, tooling, and processes now in place, we are well-positioned to support additional languages as we continue our commitment to making GitLab accessible to users worldwide. An AI-assisted  translation workflow that balances speed and quality We adopted a strategic, phased approach to processing the content through translation, prioritizing pages based on their English-language page views. The highest-traffic pages underwent AI translation first, followed by comprehensive human linguistic review, and we intentionally paused subsequent phases until these priority pages completed the full human review cycle. This deliberate sequencing allowed us to build a robust, curated translation memory and termbase from our most important content. These linguistic assets accelerated and improved quality across all remaining content. In parallel, this initial phase served as our testing ground on the technical infrastructure on the GitLab side. We used it to iterate and reinforce our CI/CD pipelines, refine our translation and post-editing AI scripts, and solidify our Translation MR review process. To provide our international users with the most current documentation while guaranteeing high-quality translated content, we implemented an AI-assisted translation workflow with human post-editing , consisting of: Phase 1: AI-powered translation. We built a custom AI translation system enriched with GitLab-specific context including style guides, GitLab UI content translations, terminology databases, and original file context. This system intelligently handles GitLab's specialized markdown syntax (GLFM) and protects elements like placeholder variables, alert boxes, Hugo shortcodes, and GitLab-specific references that standard translation tools can't process out of the box. Phase 2: Human linguistic review. Professional Japanese translators specialized in technical content then review and refine the AI translations. They work with GitLab's Japanese style guide, translation memory, and terminology database to ensure accuracy, natural language flow, and cultural appropriateness. These human-reviewed translations progressively replace the AI versions on the site. Technical challenges and solutions Localizing GitLab's extensive documentation, while maintaining our docs-as-code principles and CI/CD-driven publishing workflow, required significant technical innovation. The challenges extended beyond translation itself: we needed to preserve complex markdown syntax, maintain automated testing standards, ensure seamless content fallbacks, and create sustainable processes for continuous updates across multiple source projects. The English markdown file syntax complexity led us to developing custom code and regex in our Translation Management System (TMS) to protect codeblocks, URLs, and other functional elements that should not be exposed for translation. Due to the dynamics of how the English content is generated, we established an English fallback mechanism. Essentially, when the Japanese translation is not ready yet, the localized site seamlessly displays English content with translated navigation and UI, preventing 404s and maintaining language context via Hugo’s rendering system. We enhanced the localized navigation and linking so that it adjusts dynamically and would persist the locale. We added anchor IDs in the translated files by pre-processing the English file before it’s sent for translation. That improves the experience for people navigating to a docs page from a link. The consistent anchor ID means they can change to either language and still land in the correct place in the page. We also extended CI/CD pipelines to test localized content in Translation MRs following the same quality standards as the English docs. It allows us to catch invalid Hugo shortcodes, spaces inside links, or bare URLs. It also identifies orphaned files and redirects files with no target files. You can see the jobs that run on the MRs containing translated documentation on the GitLab project .gitlab/ci/docs.gitlab-ci.yml file . A centralized translation request system orchestrates the workflow, monitors the English files, identifies new and updated content, routes files for translation, automatically creates translation merge requests, tracks file status in translation requests and maintains an audit trail. To get docs translated we processed 430 Translation MRs with files ranging from 1-10 in each Translation MR. The result is a Japanese documentation experience that stays synchronized with English content updates, giving users faster access to critical information. Users can discover and navigate content fully in their language, with English appearing only for content that’s still in translation. They can trust GitLab’s quality standards while accessing the latest features quickly. All of this creates a sustainable, scalable foundation for future languages and documentation growth. Learn more about all the technical details in our GitLab Product Documentation Handbook page . Visit our Japanese docs site Whether you're a longtime GitLab user or just getting started, we hope this localized documentation makes your DevSecOps journey smoother and more accessible. This is just the beginning of our localization efforts, and your feedback is invaluable in helping us improve. If you notice any translation issues, have suggestions for improvement, or simply want to share your experience using the Japanese documentation, please don't hesitate to reach out. You can provide comments in our feedback issue . As we continue evolving this localization infrastructure, our immediate priorities include enhancing the search experience for Japanese users, and accelerating our continuous localization workflow to minimize the time gap between English updates and their Japanese translations. Thank you to our Japanese community for your continued support and patience as we work to serve you better. We're committed to making GitLab the best DevSecOps platform for Japanese teams, and comprehensive Japanese documentation is a crucial step in that journey. Start exploring today at docs.gitlab.com/ja-jp !",
      "published_ts": 1765411200,
      "source_name": "GitLab Engineering",
      "content_type": "technical"
    },
    {
      "url": "https://airbyte.com/blog/layers-of-agentic-data-infrastructure",
      "title": "The 9 Layers of Agentic Data Infrastructure | Airbyte",
      "summary": "Discover the 9 essential layers of agentic data infrastructure—an integrated framework that empowers AI agents to autonomously collect, process, analyze, and act on data across modern ecosystems.",
      "published_ts": 1765411200,
      "source_name": "Airbyte Blog",
      "content_type": "technical"
    },
    {
      "url": "https://dagster.io/blog/skip-kafka-use-postgres-message-queue",
      "title": "Postgres vs Kafka for Event Queues",
      "summary": "Explore how Postgres can outperform Kafka in storing and indexing event logs, especially when flexibility and familiarity matter.",
      "published_ts": 1765306777,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://www.dataengineeringweekly.com/p/data-engineering-weekly-247",
      "title": "Data Engineering Weekly #247",
      "summary": "The Weekly Data Engineering Newsletter",
      "published_ts": 1765157129,
      "source_name": "Data Engineering Weekly",
      "content_type": "technical"
    }
  ],
  "news_general": [],
  "python_analytics": [
    {
      "url": "https://dagster.io/blog/chatgpt-langchain",
      "title": "Build a GitHub Support Bot with GPT3",
      "summary": "Create a GitHub support bot using GPT3, LangChain, and Python to automate answers and improve developer UX.",
      "published_ts": 1765554388,
      "source_name": "Dagster Blog",
      "content_type": "technical"
    },
    {
      "url": "https://blog.cloudflare.com/python-workers-advancements/",
      "title": "Python Workers redux: fast cold starts, packages, and a uv-first workflow",
      "summary": "Recent advancements in Cloudflare Python Workers means fast cold starts, comprehensive package support, and a great developer experience. We explain how they were achieved and show how Python can be used to build serverless applications on Cloudflare.",
      "published_ts": 1765173600,
      "source_name": "Cloudflare Engineering",
      "content_type": "technical"
    }
  ],
  "warehouses_engines": [
    {
      "url": "https://www.databricks.com/blog/openai-gpt-52-and-responses-api-databricks-build-trusted-data-aware-agentic-systems",
      "title": "OpenAI GPT-5.2 and Responses API on Databricks: Build Trusted, Data-Aware Agentic Systems",
      "summary": "OpenAI GPT-5.2 is now available on Databricks, giving teams day one access to OpenAI’s...",
      "published_ts": 1765476025,
      "source_name": "Databricks Blog",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/introducing-aws-glue-5-1-for-apache-spark/",
      "title": "Introducing AWS Glue 5.1 for Apache Spark",
      "summary": "AWS recently announced Glue 5.1, a new version of AWS Glue that accelerates data integration workloads in AWS. AWS Glue 5.1 upgrades the Spark engines to Apache Spark 3.5.6, giving you newer Spark release along with the newer dependent libraries so you can develop, run, and scale your data integration workloads and get insights faster. In this post, we describe what’s new in AWS Glue 5.1, key highlights on Spark and related libraries, and how to get started on AWS Glue 5.1.",
      "published_ts": 1765315755,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    },
    {
      "url": "https://aws.amazon.com/blogs/big-data/sap-data-ingestion-and-replication-with-aws-glue-zero-etl/",
      "title": "SAP data ingestion and replication with AWS Glue zero-ETL",
      "summary": "AWS Glue zero-ETL with SAP now supports data ingestion and replication from SAP data sources such as Operational Data Provisioning (ODP) managed SAP Business Warehouse (BW) extractors, Advanced Business Application Programming (ABAP), Core Data Services (CDS) views, and other non-ODP data sources. Zero-ETL data replication and schema synchronization writes extracted data to AWS services like Amazon Redshift, Amazon SageMaker lakehouse, and Amazon S3 Tables, alleviating the need for manual pipeline development. In this post, we show how to create and monitor a zero-ETL integration with various ODP and non-ODP SAP sources.",
      "published_ts": 1765235515,
      "source_name": "Redshift / AWS Big Data",
      "content_type": "technical"
    }
  ]
}